name: Scrape Bears Articles

on:
  schedule:
    - cron: '0 12 * * *'  # 6 AM CST (UTC-6) / 7 AM CDT (UTC-5) — GitHub Actions has no timezone support, so this shifts 1 hour during daylight saving (mid-Mar to early-Nov)
  workflow_dispatch:       # Manual trigger — useful for testing

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # needed to commit articles.json back to the repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        run: node scripts/scraper.js

      - name: Check for changes
        id: changes
        run: |
          if git diff --quiet public/data/articles.json; then
            echo "No changes to articles.json"
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "Articles updated"
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push updated articles
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add public/data/articles.json
          git commit -m "chore: daily article scrape $(date -u '+%Y-%m-%d')"
          git push
